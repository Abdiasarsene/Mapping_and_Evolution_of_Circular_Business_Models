import random
import re

# ğŸ“Œ Chemins des fichiers
input_file = r"D:\Projects\IT\Data Science & IA\Mapping_Evolution_of_Circular_Business_Models\merged_text.txt"  
output_file = "filtered_text.txt"

# ğŸ”¹ Ã‰tape 1 : Lire le fichier
with open(input_file, "r", encoding="utf-8") as f:
    lines = f.readlines()

# ğŸ”¹ Ã‰tape 2 : Tronquer 35 % des textes alÃ©atoirement
num_lines = len(lines)
selected_lines = random.sample(lines, int(num_lines * 0.35))  # Prendre 35 %

# ğŸ”¹ Ã‰tape 3 : Nettoyer les textes
def clean_text(text):
    text = re.sub(r"\s+", " ", text)  # Supprimer les espaces multiples
    text = re.sub(r"[^a-zA-Z0-9Ã€-Ã¿\s]", "", text)  # Enlever caractÃ¨res spÃ©ciaux
    return text.strip()

cleaned_lines = [clean_text(line) for line in selected_lines if len(line.split()) > 3]  # Supprime les phrases trop courtes

# ğŸ”¹ Ã‰tape 4 : Sauvegarder le texte nettoyÃ©
with open(output_file, "w", encoding="utf-8") as f:
    f.write("\n".join(cleaned_lines))

print(f"âœ… Extraction et nettoyage terminÃ©s ! RÃ©sultat : {output_file}")
